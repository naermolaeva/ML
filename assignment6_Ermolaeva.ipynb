{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "d674e6a435c5949a67755544c686e2ebd00b660b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "import nltk\n",
    "import gensim\n",
    "import spacy\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch as tt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch import autograd\n",
    "\n",
    "from torchtext.data import Field, LabelField, BucketIterator, ReversibleField, TabularDataset\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "82bf9c90f2ff6e8cee85b099a2d526d1821d88e1"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "a4570396934f93303b1d7b90976e92e4eaf36668"
   },
   "outputs": [],
   "source": [
    "spacy_en = spacy.load('en')\n",
    "spacy_en.remove_pipe('tagger')\n",
    "spacy_en.remove_pipe('ner')\n",
    "\n",
    "def tokenizer(text): # create a tokenizer function\n",
    "#     return [tok.lemma_ for tok in spacy_en.tokenizer(text) if tok.text.isalpha()]\n",
    "    return [tok.lemma_ for tok in spacy_en.tokenizer(text)] # not only letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "56546cf266ddc0e54d09968cd81e72b06d9e7675"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../input/train-balanced-sarcasm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "111a8ce1c0ab083c84e3034638b24431b403624c"
   },
   "outputs": [],
   "source": [
    "data = data[['label', 'comment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "c7baa4c7ecf31ce72255384462963af914d6dbc5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "0fbfb66551e235411bfdcd011ac84ced50ef1dcd"
   },
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "e5d79c49007a6566da31ce9c702a33c6b67c8d9b"
   },
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "910bbff60a259afdfd7481bc11092028b524e82b"
   },
   "outputs": [],
   "source": [
    "train_dataset.to_csv('train_ds.csv', encoding='utf-8', index=False)\n",
    "test_dataset.to_csv('test_ds.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "ebb06360b6206a34a101370feb9a6edbd4eac752"
   },
   "outputs": [],
   "source": [
    "classes={\n",
    "    '0': 0,\n",
    "    '1': 1\n",
    "}\n",
    "\n",
    "TEXT = Field(include_lengths=True, batch_first=True, \n",
    "             tokenize=tokenizer,\n",
    "             eos_token='<eos>',\n",
    "             lower=True,\n",
    "             stop_words=nltk.corpus.stopwords.words('english')\n",
    "            )\n",
    "\n",
    "LABEL = LabelField(dtype=tt.int64, use_vocab=True, preprocessing=lambda x: classes[x])\n",
    "\n",
    "train = TabularDataset('train_ds.csv', format='csv', \n",
    "                         fields=[('label', LABEL), ('text', TEXT)], \n",
    "                         skip_header=True)\n",
    "\n",
    "test = TabularDataset('test_ds.csv', format='csv', \n",
    "                         fields=[('label', LABEL), ('text', TEXT)], \n",
    "                         skip_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "990b432e52155cdb3d5f0b6e24d906c7c0462f6a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.6B.zip: 862MB [06:34, 2.19MB/s]                               \n",
      "100%|█████████▉| 399564/400000 [00:46<00:00, 8429.10it/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "31511"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.build_vocab(train, min_freq=5, vectors='glove.6B.300d')\n",
    "len(TEXT.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "3c44e92ad7093ffda61598f9126b9621f0dd0274"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|█████████▉| 399564/400000 [01:00<00:00, 8429.10it/s]"
     ]
    }
   ],
   "source": [
    "embed_matrix = TEXT.vocab.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "a9c2e924a7e7b3e056f6492556b37d50b18ab175"
   },
   "outputs": [],
   "source": [
    "LABEL.build_vocab(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "e547246564b9b39583e1397249bd1545aa56ed5c"
   },
   "outputs": [],
   "source": [
    "# wv_from_bin = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "# embed_matrix = tt.FloatTensor(wv_from_bin.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "d3856e16e836247fdeaa7bebbc50720c13f595a3"
   },
   "outputs": [],
   "source": [
    "train, valid = train.split(0.9, stratified=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "5c0e1d0bb36df8a0cfb2e66a9a41c7fc43211e78"
   },
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, embed_matrix):\n",
    "        super(MyModel, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding.from_pretrained(embed_matrix, freeze=False)\n",
    "        self.rnn = nn.LSTM(input_size=embed_size,\n",
    "                           hidden_size=hidden_size,\n",
    "                           bidirectional=True,\n",
    "                           batch_first=True\n",
    "                          )\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size * 2 * 2, 512)\n",
    "        \n",
    "#         self.i1h = nn.Linear(hidden_size * 2, 256)\n",
    "#         self.i2h = nn.Linear(hidden_size, 128)\n",
    "#         self.i2o = nn.Linear(128, 2)\n",
    "        \n",
    "#         self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "\n",
    "#     def init_hidden(self, batch_size, hidden_size):\n",
    "#         return (autograd.Variable(tt.zeros(1, batch_size, hidden_size)),\n",
    "#                 autograd.Variable(tt.zeros(1, batch_size, hidden_size)))\n",
    "        \n",
    "        \n",
    "    def forward(self, batch):\n",
    "        \n",
    "        x, x_lengths = batch.text\n",
    "        \n",
    "        x = x.cuda()\n",
    "        batch.label = batch.label.cuda()\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "\n",
    "        if x_lengths is not None:\n",
    "            x_lengths = x_lengths.view(-1).tolist()\n",
    "            x = nn.utils.rnn.pack_padded_sequence(x, x_lengths, batch_first=True)\n",
    "            \n",
    "        _, (hidden, cell) = self.rnn(x)\n",
    "        \n",
    "        hidden = hidden.transpose(0,1)\n",
    "        cell = cell.transpose(0,1)\n",
    "        hidden = hidden.contiguous().view(hidden.size(0),-1)\n",
    "        cell = cell.contiguous().view(cell.size(0),-1)\n",
    "        x = tt.cat([hidden, cell], dim=1).squeeze(1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "#         x = F.relu(self.fc(x))\n",
    "#         x = self.dropout(x)\n",
    "\n",
    "#         x = F.relu(self.i2h(x))\n",
    "#         x = self.dropout(x)\n",
    "\n",
    "#         x = F.relu(self.i1h(x))\n",
    "#         x = self.dropout(x)\n",
    "\n",
    "#         x = self.i2o(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "935fb2fb54cd412b542f7848efa77711d69f42c5"
   },
   "outputs": [],
   "source": [
    "tt.cuda.empty_cache()\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "model = MyModel(len(TEXT.vocab.itos),\n",
    "                embed_size=300,\n",
    "                embed_matrix=embed_matrix,\n",
    "                hidden_size=512\n",
    "               )\n",
    "\n",
    "model = model.cuda()\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train, valid, test),\n",
    "    batch_sizes=(batch_size, batch_size, batch_size),\n",
    "    shuffle=True,\n",
    "    sort_key=lambda x: len(x.text),\n",
    "    sort_within_batch=True\n",
    ")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=5)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "241f16c1f7af4011edabee34335a61e5a245b396"
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(predictions, Y):\n",
    "    max_vals, max_indices = tt.max(predictions.data, 1)\n",
    "    acc = (max_indices == Y).sum().data.cpu().numpy() / max_indices.size()[0]\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "58382c7010266b9a6e568777d86f79864d81d105"
   },
   "outputs": [],
   "source": [
    "def evaluate_test_accuracy(model, test_iterator, criterion):\n",
    "    epoch_accuracy = 0\n",
    "    \n",
    "    model.eval()\n",
    "    n_batches = len(test_iterator)\n",
    "    \n",
    "    with tt.no_grad():\n",
    "        for batch in test_iterator:\n",
    "            pred = model(batch)\n",
    "            accuracy = calculate_accuracy(pred, batch.label)\n",
    "            epoch_accuracy += accuracy.item()\n",
    "        \n",
    "    return epoch_accuracy / n_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "be766af9b21170819bbd783c2ac864770dfad01f"
   },
   "outputs": [],
   "source": [
    "def _train_epoch(model, iterator, optimizer, criterion, curr_epoch):\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    n_batches = len(iterator)\n",
    "    iterator = tqdm_notebook(iterator, total=n_batches, desc='epoch %d' % (curr_epoch), leave=True)\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred = model(batch)\n",
    "        loss = criterion(pred, batch.label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        curr_loss = loss.data.cpu().detach().item()\n",
    "        \n",
    "        loss_smoothing = i / (i+1)\n",
    "        running_loss = loss_smoothing * running_loss + (1 - loss_smoothing) * curr_loss\n",
    "\n",
    "        iterator.set_postfix(loss='%.5f' % running_loss)\n",
    "        \n",
    "        accuracy = calculate_accuracy(pred, batch.label)\n",
    "        epoch_acc += accuracy.item()\n",
    "\n",
    "    return running_loss, epoch_acc / n_batches\n",
    "\n",
    "def _test_epoch(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    n_batches = len(iterator)\n",
    "    with tt.no_grad():\n",
    "        for batch in iterator:\n",
    "            pred = model(batch)\n",
    "            loss = criterion(pred, batch.label)\n",
    "            epoch_loss += loss.data.item()\n",
    "            \n",
    "            accuracy = calculate_accuracy(pred, batch.label)\n",
    "            epoch_acc += accuracy.item()\n",
    "\n",
    "    return epoch_loss / n_batches, epoch_acc / n_batches\n",
    "\n",
    "\n",
    "def nn_train(model, train_iterator, valid_iterator, criterion, optimizer, test_iterator, n_epochs=100,\n",
    "             scheduler=None, early_stopping=0):\n",
    "\n",
    "    prev_loss = 100500\n",
    "    es_epochs = 0\n",
    "    best_epoch = None\n",
    "    history = pd.DataFrame()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss, train_acc = _train_epoch(model, train_iterator, optimizer, criterion, epoch)\n",
    "        valid_loss, valid_acc = _test_epoch(model, valid_iterator, criterion)\n",
    "\n",
    "        valid_loss = valid_loss\n",
    "        print('validation loss %.5f' % valid_loss)\n",
    "\n",
    "#         print(f'| Train Loss: {train_loss:.5f} | Train Accuracy: {train_acc:.5f} | Validation Loss: {valid_loss:.5f} | Validation Accuracy: {valid_acc:.5f} |')\n",
    "\n",
    "        record = {'epoch': epoch, 'train_loss': train_loss, 'valid_loss': valid_loss}\n",
    "        history = history.append(record, ignore_index=True)\n",
    "\n",
    "        if early_stopping > 0:\n",
    "            if valid_loss > prev_loss:\n",
    "                es_epochs += 1\n",
    "            else:\n",
    "                es_epochs = 0\n",
    "\n",
    "            if es_epochs >= early_stopping:\n",
    "                best_epoch = history[history.valid_loss == history.valid_loss.min()].iloc[0]\n",
    "                print('Early stopping! best epoch: %d val %.5f' % (best_epoch['epoch'], best_epoch['valid_loss']))\n",
    "                break\n",
    "\n",
    "            prev_loss = min(prev_loss, valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "70f75ce7d4e41a5ce758d22708af93c7a192f737"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c817be57a385450283a242ec018abc74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch 0', max=1422, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss 0.55399\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efed5081a853475cac65bfba39473bc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch 1', max=1422, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss 0.54624\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6663819666a4e0f932c43e37f19db74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch 2', max=1422, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss 0.55383\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c816c2ddebb4a5a88be1a4dc97f24df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch 3', max=1422, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss 0.58839\n",
      "Early stopping! best epoch: 1 val 0.54624\n"
     ]
    }
   ],
   "source": [
    "nn_train(model, train_iterator, valid_iterator, criterion, optimizer, test_iterator, scheduler=scheduler, \n",
    "         n_epochs=10, early_stopping=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "e35aacc5cf6552f5699d9e2047e0fce0e6a57452"
   },
   "outputs": [],
   "source": [
    "def evaluate_test_accuracy(model, test_iterator, criterion):\n",
    "    epoch_accuracy = 0\n",
    "    \n",
    "    model.eval()\n",
    "    n_batches = len(test_iterator)\n",
    "    \n",
    "    with tt.no_grad():\n",
    "        for batch in test_iterator:\n",
    "            pred = model(batch)\n",
    "            accuracy = calculate_accuracy(pred, batch.label)\n",
    "            epoch_accuracy += accuracy.item()\n",
    "        \n",
    "    return epoch_accuracy / n_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "1a537a9b3c5786d48e1724f632fe700aa6225dc5"
   },
   "outputs": [],
   "source": [
    "test_accuracy = evaluate_test_accuracy(model, test_iterator, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5e8c2c57e5efabc8436b6873e2444df4867a661c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.71208\n"
     ]
    }
   ],
   "source": [
    "print('Test Accuracy: %.5f' % test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
